{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netta/users/ojfrancois/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/mnt/netta/users/ojfrancois/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/mnt/netta/users/ojfrancois/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/mnt/netta/users/ojfrancois/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/mnt/netta/users/ojfrancois/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/tmp/ipykernel_6731/3229852722.py:298: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_can_use = pd.read_sql(\"SELECT * FROM CAN_USE\", cnxn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CAN_USE</th>\n",
       "      <th>CTR_ID</th>\n",
       "      <th>ENS_ID</th>\n",
       "      <th>CO2EMISSION</th>\n",
       "      <th>ENSCONSUMPTION</th>\n",
       "      <th>ENSPRODUCTION</th>\n",
       "      <th>SOURCEYEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>FRA</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113606e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2</td>\n",
       "      <td>5.750623e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.209381</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>FRA</td>\n",
       "      <td>4</td>\n",
       "      <td>3.913502e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>FRA</td>\n",
       "      <td>5</td>\n",
       "      <td>2.514371e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.500679</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>562</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2.003841e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>563</td>\n",
       "      <td>USA</td>\n",
       "      <td>5</td>\n",
       "      <td>2.054157e+12</td>\n",
       "      <td>8269.321289</td>\n",
       "      <td>8232.885742</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>564</td>\n",
       "      <td>USA</td>\n",
       "      <td>6</td>\n",
       "      <td>1.577342e+10</td>\n",
       "      <td>45.478786</td>\n",
       "      <td>45.478786</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>565</td>\n",
       "      <td>USA</td>\n",
       "      <td>7</td>\n",
       "      <td>3.364257e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>566</td>\n",
       "      <td>USA</td>\n",
       "      <td>8</td>\n",
       "      <td>4.546789e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_CAN_USE CTR_ID  ENS_ID   CO2EMISSION  ENSCONSUMPTION  ENSPRODUCTION  \\\n",
       "0            31    FRA       1  3.113606e+10        0.000000       0.000000   \n",
       "1            32    FRA       2  5.750623e+10        0.000000     282.209381   \n",
       "2            33    FRA       3  0.000000e+00        0.000000       0.000000   \n",
       "3            34    FRA       4  3.913502e+10        0.000000       0.000000   \n",
       "4            35    FRA       5  2.514371e+10        0.000000      76.500679   \n",
       "..          ...    ...     ...           ...             ...            ...   \n",
       "531         562    USA       4  2.003841e+12        0.000000       0.000000   \n",
       "532         563    USA       5  2.054157e+12     8269.321289    8232.885742   \n",
       "533         564    USA       6  1.577342e+10       45.478786      45.478786   \n",
       "534         565    USA       7  3.364257e+10        0.000000       0.000000   \n",
       "535         566    USA       8  4.546789e+12        0.000000       0.000000   \n",
       "\n",
       "     SOURCEYEAR  \n",
       "0          1971  \n",
       "1          1971  \n",
       "2          1971  \n",
       "3          1971  \n",
       "4          1971  \n",
       "..          ...  \n",
       "531        2015  \n",
       "532        2015  \n",
       "533        2015  \n",
       "534        2015  \n",
       "535        2015  \n",
       "\n",
       "[536 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pymssql as pymssql\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import shapely.geometry as geom\n",
    "\n",
    "#Connection à la base \n",
    "cnxn=pymssql.connect(server='info-mssql-etd', user='etd14',password='x578tcb5',database='BDEquipe14')\n",
    "\n",
    "# # On déclare un curseur\n",
    "cursor=cnxn.cursor()\n",
    "\n",
    "# #csv contenant le nom de tous les pays avec son code et la région auquel il appartient \n",
    "countryRegion= pd.read_csv('pays-region.csv',delimiter=';')\n",
    "\n",
    "# #csv contenant la lat , lon et le code pays \n",
    "latLonCountry= pd.read_csv('LatLonPays.csv')\n",
    "\n",
    "# #csv contenant  les GDP\n",
    "GDP=pd.read_csv('GDP2.csv')\n",
    "GDP = GDP[['Country Code'] + [str(i) for i in range(1960, 2023)]].fillna(0)\n",
    "\n",
    "#csv contenant  les GHG\n",
    "GHG=pd.read_csv('GHG.csv')\n",
    "GHG = GHG[['Country Code'] + [str(i) for i in range(1960, 2023)]].fillna(0)\n",
    "#csv contenant  les population\n",
    "POP=pd.read_csv('population.csv')\n",
    "POP = POP[['Country Code'] + [str(i) for i in range(1960, 2023)]].fillna(0)\n",
    "\n",
    "sources= pd.read_csv('ENS&SCT/sources.csv',delimiter=';')\n",
    "sectors=pd.read_csv('ENS&SCT/secteurs.csv')\n",
    "\n",
    "df = gp.read_file('countries.geojson')\n",
    "\n",
    "def linkCoordToCountry(name):\n",
    "    df2 = pd.read_csv(name)\n",
    "    df2['coords'] = list(zip(df2['lon'],df2['lat']))\n",
    "    df2['coords'] = df2['coords'].apply(geom.Point)\n",
    "    points = gp.GeoDataFrame(df2, geometry='coords', crs=df.crs)\n",
    "    pointInPolys = gp.tools.sjoin(points, df, op=\"within\", how='left')\n",
    "    return pointInPolys[[\"lat\",\"lon\",\"crs\",\"total\",\"ISO_A3\"]].fillna(\"\")\n",
    "\n",
    "seaLvl=linkCoordToCountry(\"sealvl.csv\")\n",
    "TX35=linkCoordToCountry(\"TX35.csv\")\n",
    "meanTemp=linkCoordToCountry(\"meanTemp.csv\")\n",
    "meanTempChange=linkCoordToCountry(\"meanTempChange.csv\")\n",
    "precipit=linkCoordToCountry(\"totalPrecipit.csv\")\n",
    "\n",
    "def delete(table):\n",
    "    cursor.execute(\"DELETE FROM \"+table)\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les pays\n",
    "def importCountries():\n",
    "    pays = countryRegion[['name', 'geo']]\n",
    "    for index, row in pays.iterrows():\n",
    "        cursor.execute(\"INSERT INTO  T_COUNTRY_CTR (CTR_ID, CTR_NAME) VALUES (%s, %s)\", (row['geo'][:3].upper(), row['name'][:32]))\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les régions\n",
    "def importRegions():\n",
    "    region = countryRegion[['eight_regions']]\n",
    "    region = region.drop_duplicates()\n",
    "    region = region.dropna()\n",
    "    for index, row in region.iterrows():\n",
    "        cursor.execute(\"INSERT INTO T_REGION_REG (REG_NAME) VALUES (%s)\", (row['eight_regions'][:255]))\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les pays dans les régions\n",
    "def importIsOn():\n",
    "    isOn = countryRegion[['eight_regions','geo']]\n",
    "    isOn = isOn.dropna()\n",
    "    for index, row in isOn.iterrows():\n",
    "        cursor.execute(\"INSERT INTO  IS_ON (REG_ID,CTR_ID) VALUES ((select REG_ID from T_REGION_REG where REG_NAME=%s),%s)\", (row['eight_regions'][:255],row['geo'][:3].upper()))\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les indicateurs\n",
    "def importIndicator():\n",
    "    for index, row in POP.iterrows():\n",
    "        ctr_id = row['Country Code'][:3]\n",
    "        for year in range(1960, 2023):\n",
    "            year_str = str(year)\n",
    "            gdp_value = GDP.loc[GDP['Country Code'] == row['Country Code'], year_str].values[0]\n",
    "            ghg_value = GHG.loc[GHG['Country Code'] == row['Country Code'], year_str].values[0]\n",
    "            pop_value = row[year_str]\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM T_COUNTRY_CTR WHERE CTR_ID = %s\", (ctr_id,))\n",
    "            if cursor.fetchone()[0] > 0:\n",
    "                cursor.execute(\"INSERT INTO T_INDICATOR_IND (CTR_ID, IND_GDP, IND_GHG, IND_POPULATION, IND_YEAR) VALUES (%s, %s, %s, %s, %s)\", \n",
    "                               (ctr_id, gdp_value, ghg_value, pop_value, year))\n",
    "            else:\n",
    "                print(f\"Le CTR_ID {ctr_id} n'existe pas dans T_COUNTRY_CTR\")\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les données géographiques\n",
    "def importGeo():\n",
    "        for index, row in seaLvl.iterrows():\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM T_COUNTRY_CTR WHERE CTR_ID = %s\", (row['ISO_A3'],))\n",
    "            if cursor.fetchone()[0] > 0:\n",
    "                cursor.execute(\"INSERT INTO T_GEOGRAPHICALDATA_GEO (CTR_ID, GEO_CRS, GEO_MEANTEMP, GEO_TX35, GEO_SEALVL, GEO_MEANTEMPCHANGE, GEO_TOTALPRECIPIT, GEO_LAT, GEO_LON) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "                            (row['ISO_A3'], row['crs'], meanTemp.loc[index, 'total'], TX35.loc[index, 'total'], seaLvl.loc[index, 'total'], meanTempChange.loc[index, 'total'], precipit.loc[index, 'total'], row['lat'], row['lon']))\n",
    "            else:\n",
    "                print(f\"Le CTR_ID {row['ISO_A3']} n'existe pas dans T_COUNTRY_CTR\")\n",
    "        cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les sources d'énergie\n",
    "def importSources():\n",
    "    for index, row in sources.iterrows():\n",
    "        cursor.execute(\"INSERT INTO  T_ENERGYSOURCE_ENS (ENS_NAME,ENS_ISFOSSIL) VALUES (%s,%s)\", (row['name'][:32], row['isFossil']))\n",
    "    cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les secteurs\n",
    "def importSectors():\n",
    "    for index, row in sectors.iterrows():\n",
    "        cursor.execute(\"INSERT INTO  T_SECTOR_SCT (SCT_NAME) VALUES (%s)\", (row['name'][:32]))\n",
    "    cnxn.commit() \n",
    "\n",
    "# Fonction pour obtenir le multiplicateur de CO2\n",
    "def get_co2_multiplier(country_code):\n",
    "    match country_code:\n",
    "        case 'FRA':\n",
    "            return 0.31\n",
    "        case 'DNK':\n",
    "            return 0.5\n",
    "        case 'DEU':\n",
    "            return 0.441\n",
    "        case 'CIV':\n",
    "            return 0.62\n",
    "        case 'CHN':\n",
    "            return 0.53\n",
    "        case 'IND':\n",
    "            return 0.82\n",
    "        case 'USA':\n",
    "            return 0.53\n",
    "\n",
    "# Fonction pour importer les émissions de CO2 par secteur\n",
    "def importSectorPays():\n",
    "    filenames = glob.glob(\"ENS&SCT/EmissionSecteur/*.csv\")\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        country_code = filename[-7:-4].upper()  # Extrayant les 3 dernières lettres en majuscules\n",
    "        df = pd.read_csv(filename,delimiter=';',index_col=0)\n",
    "        df = df.rename_axis(\"date\").reset_index()\n",
    "        df[\"date\"] = df['date'].str[0:4]\n",
    "        df['country_code'] = country_code\n",
    "        df['co2_muli'] = get_co2_multiplier(country_code)\n",
    "        df['co2_muli'] = df['co2_muli'].astype(float)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    for index, row in merged_df.iterrows():\n",
    "            date = row['date']\n",
    "            for sector, emission in row.items():\n",
    "                if sector not in ['date', 'country_code', 'co2_muli']:\n",
    "                    cursor.execute(\"SELECT SCT_ID FROM T_SECTOR_SCT WHERE SCT_NAME = %s\", (sector,))\n",
    "                    sector_id = cursor.fetchone()[0]\n",
    "                    twhtokwgh = float(emission.replace(',','.')) * 1000000000\n",
    "                    co2emission = twhtokwgh * row['co2_muli']    \n",
    "                    cursor.execute(\"INSERT INTO HAVE (CTR_ID, SCT_ID, CO2EMISSION, SECTORYEAR) VALUES (%s, %s, %s, %s)\",\n",
    "                                    (row['country_code'], sector_id, co2emission, date))\n",
    "            cnxn.commit()\n",
    "\n",
    "# Fonction pour importer les sources d'énergie par pays (Elle réalise la jointure sur de plusieurs fichiers afin d'obtenir les données d'émission et de sources d'énergie par pays)\n",
    "def importSourcesPays():\n",
    "    filenames_fe = glob.glob(\"ENS&SCT/EmissionSources/FE/*.csv\")\n",
    "    filenames_pec = glob.glob(\"ENS&SCT/EmissionSources/PEC/*.csv\")\n",
    "    filenames_pep = glob.glob(\"ENS&SCT/EmissionSources/PEP/*.csv\")\n",
    "    \n",
    "    data_fe = {}\n",
    "    data_pec = {}\n",
    "    data_pep = {}\n",
    "    \n",
    "    for filename in filenames_fe:\n",
    "        country_code = filename[-7:-4].upper()\n",
    "        df = pd.read_csv(filename, delimiter=';', index_col=0)\n",
    "        df = df.rename_axis(\"date\").reset_index()\n",
    "        df[\"date\"] = df['date'].str[0:4]\n",
    "        df['country_code'] = country_code\n",
    "        df['co2_muli'] = get_co2_multiplier(country_code)\n",
    "        df['co2_muli'] = df['co2_muli'].astype(float)\n",
    "        data_fe[country_code] = df\n",
    "    \n",
    "    for filename in filenames_pec:\n",
    "        country_code = filename[-7:-4].upper()\n",
    "        df = pd.read_csv(filename, delimiter=';', index_col=0)\n",
    "        df = df.rename_axis(\"date\").reset_index()\n",
    "        df[\"date\"] = df['date'].str[0:4]\n",
    "        df['country_code'] = country_code\n",
    "        data_pec[country_code] = df\n",
    "\n",
    "    for filename in filenames_pep:\n",
    "        country_code = filename[-7:-4].upper()\n",
    "        df = pd.read_csv(filename, delimiter=';', index_col=0)\n",
    "        df = df.rename_axis(\"date\").reset_index()\n",
    "        df[\"date\"] = df['date'].str[0:4]\n",
    "        df['country_code'] = country_code\n",
    "        data_pep[country_code] = df\n",
    "    \n",
    "    # Liaison des données d'émission de sources d'énergie avec les données de consommation et de production par pays\n",
    "    for country_code in data_fe:\n",
    "        df_fe = data_fe[country_code]\n",
    "        df_pec = data_pec.get(country_code)\n",
    "        df_pep = data_pep.get(country_code)\n",
    "        \n",
    "        for index, row in df_fe.iterrows():\n",
    "            date = row['date']\n",
    "            for source, value in row.items():\n",
    "                if source not in ['date', 'country_code', 'co2_muli'] and source is not np.nan and not pd.isna(value):\n",
    "                    cursor.execute(\"SELECT ENS_ID FROM T_ENERGYSOURCE_ENS WHERE ENS_NAME = %s\", (source,))\n",
    "                    result = cursor.fetchone()\n",
    "                    if result:\n",
    "                        source_id = result[0]\n",
    "                        if isinstance(value, str):\n",
    "                            value = value.replace(',', '.')\n",
    "                        try:\n",
    "                            twhtokwgh = float(value) * 1000000000\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                        co2emission = twhtokwgh * row['co2_muli']\n",
    "                        \n",
    "                        consumption = 0\n",
    "                        production = 0\n",
    "                        \n",
    "                        if df_pec is not None and source in df_pec.columns:\n",
    "                            consumption_values = df_pec.loc[df_pec['date'] == date, source].values\n",
    "                            if len(consumption_values) > 0 and not pd.isna(consumption_values[0]):\n",
    "                                consumption = float(consumption_values[0].replace(',', '.') if isinstance(consumption_values[0], str) else consumption_values[0])\n",
    "                        \n",
    "                        if df_pep is not None and source in df_pep.columns:\n",
    "                            production_values = df_pep.loc[df_pep['date'] == date, source].values\n",
    "                            if len(production_values) > 0 and not pd.isna(production_values[0]):\n",
    "                                production = float(production_values[0].replace(',', '.') if isinstance(production_values[0], str) else production_values[0])\n",
    "                        \n",
    "                        cursor.execute(\n",
    "                            \"INSERT INTO CAN_USE (CTR_ID, ENS_ID, Co2Emission, ENSCONSUMPTION, ENSPRODUCTION, SOURCEYEAR) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                            (row['country_code'], source_id, co2emission, consumption, production, date)\n",
    "                        )\n",
    "    cnxn.commit()\n",
    "\n",
    "def clearAll():\n",
    "    delete(\"CAN_USE\")\n",
    "    delete(\"HAVE\")\n",
    "    delete(\"T_GEOGRAPHICALDATA_GEO\")\n",
    "    delete(\"T_ENERGYSOURCE_ENS\")\n",
    "    delete(\"T_SECTOR_SCT\")\n",
    "    delete(\"T_INDICATOR_IND\")\n",
    "    delete(\"IS_ON\")\n",
    "    delete(\"T_REGION_REG\")\n",
    "    delete(\"T_COUNTRY_CTR\")\n",
    "\n",
    "def importAll():\n",
    "    clearAll()\n",
    "    importCountries()\n",
    "    importRegions()\n",
    "    importIsOn()\n",
    "    importIndicator()\n",
    "    importGeo()\n",
    "    importSources()\n",
    "    importSectors()\n",
    "    importSectorPays()\n",
    "    importSourcesPays()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
